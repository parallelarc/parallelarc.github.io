[
  {
    "id": 3938252452,
    "number": 9,
    "title": "高继扬 - 决策备忘录",
    "content": "## 成长路径与职业选择\n\n- 擅长通过归纳总结方法论弥补天赋差距\n- 工程师思维训练：拆解复杂问题至子问题，测量指标，逐层验证\n- 选择自动驾驶作为AI在物理世界的第一个形态\n- 在Waymo学习到自动驾驶系统完整架构，识别大公司病\n- 在Momenta学会以客户为中心：站在客户角度挖掘需求\n\n---\n\n## 具身智能的技术哲学\n\n- Tesla采用AI Native设计端到端架构，Waymo采用Robotics模块化拆分\n- AI方法论追求整体Benchmark性能提升，容忍部分Case变差\n- Robotics方法论分模块解决Corner Case，系统可解释性强但迭代慢\n- 长期壁垒建立在物理世界数据闭环，必须拥有数据载体(整机), 必须软硬结合同步推进\n- 中短期商品形态是整机+智能形成的物理实体\n- 提出\"智能定义本体\"：从智能需求出发设计本体形态\n- 真实数据vs仿真：99.9%自动驾驶问题由路测数据解决，仿真Gap大\n- 智能总成本=数据获取+训练+团队，高质量数据降低训练成本\n- 数据成本与扩展：实际成本200-250元/小时，10万小时约等于人从出生到18岁与物理世界交互总时长，通过众包+真实场景可扩展\n- 数据金字塔定义应来自智能需求，各类型数据混合比例需实验确定\n- 数据类型包括：Robot-Centric（真机遥操）、Human-Centric（UMI外骨骼/采集手套）、POV、仿真数据\n- 动作大类定义：Carry、Pick、Pack、Fold、Operate五类动作\n- 坚持端到端和数据驱动，PI0推出VLA范式后快速调整跟进\n\n---\n\n## 创业战略与商业模式\n\n- 跨越鸿沟：从开发者市场（学术型→企业研究型→生产力型）走向生产力市场\n- 24年切入高校实验室建立数据闭环和客户反馈\n- 24年：整机+供应链补课，25年：数据+智能体系搭建，26年：场景+应用落地\n- 步步为营策略：避免全面铺开，按优先级集中资源\n- 创新不能脱离整个具身智能价值链条，算法传播周期最短\n- 理想主义需建立在每天算ROI基础上：长期战略价值贡献+短期收益价值贡献\n- 场景筛选标准：供给侧（速度80-90%人类、精度厘米级、泛化性零到少样本），需求侧（速度不能太高、失效成本低、有爆发力、全球化）\n\n---\n\n## 组织管理与价值观\n\n- 合伙人机制：舍得分享股权，构建六边形能力互补团队（机电、算法、商业化、CFO）\n- 实事求是根据结果调整：业绩好分配更多资源，业绩不好优化或支持内部创业\n- 以客户为中心：上游对下游、平台对交付团队均为客户关系\n- 身先士卒：创始人一线解决客户问题，树立榜样，要求合伙人同样执行\n- 技术愿景：像培训人一样培训机器人（几次示范+几次演练可稳定自主完成任务）\n- 当下重要Bet：在生产力场景实现万台出货量\n- 很早形成不在意他人评价的状态，关注目标和正在做正确的事\n- 喜欢面对真实，哪怕真相残酷\n- 向宇树学习整机供应链深入整合，向PI学习前沿算法但注重效率提升\n\n---\n\n## 创业历程与关键决策\n\n- 创业时机：ChatGPT让世界再次相信AI，量产自动驾驶+Tesla人形机器人让端侧智能可能\n- 最初想做末端配送，快速否定后切换到轮式双臂聚焦操作\n- 融资靠团队非故事：IDG领投、百度风投、金沙江（予彤后退出）\n- 天使投资人接受错误和不完美：想说做的事应该不Work，但投了\n- 两年时间估值从3亿（24年1月）增长到100亿（26年），约30倍\n- 组织从十几人扩张到200多人，每3-5个月局部调整阵型\n- 最新轮次：产业资本（吉利、北汽）+ PE/一二级Crossover基金(正心谷、金鼎等), 6家老股东Pro rata，3-4家Super（凯辉、今日资本、襄禾等）\n",
    "createdAt": "2026-02-13T17:34:13Z",
    "updatedAt": "2026-02-13T17:34:13Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "podcast"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/9",
    "commentsCount": 0,
    "excerpt": "成长路径与职业选择 - 擅长通过归纳总结方法论弥补天赋差距 - 工程师思维训练：拆解复杂问题至子问题，测量指标，逐层验证 - 选择自动驾驶作为AI在物理世界的第一个形态 - 在Waymo学习到自动驾驶系统完整架构，识别大公司病 - 在Momenta学会以客户为中心：站在客户角度挖掘需求 ---  具..."
  },
  {
    "id": 3894502715,
    "number": 8,
    "title": "范浩强高阳 - 决策备忘录",
    "content": "**访谈来源**：晚点聊 LateTalk 第149期\n**嘉宾**：范浩强（原力灵机联创）、高阳（千寻智能联创兼首席科学家）\n\n---\n\n## 一、具身智能测评：从Demo工程到科学评测\n\n### RoboChallenge平台设计理念\n\n- Robotics研究长期依赖cherry-pick的demo视频，录100遍取1条成功展示\n- 学术界最佳论文也只测试3-4个任务，且不同论文任务不统一\n- 真机测试方差大，需大规模重复测试（数百次）才能控制方差\n- RoboChallenge采用Fine-tune设定：30个任务，每个任务约1000条示范数据\n\n### Table30任务设计逻辑\n\n- 30个任务由内部研究员\"画钩\"设计，事后分析考点分布合理\n- 每个任务有独特难点，考点覆盖丰富\n- 碎纸任务：纸遮挡手眼，考验克服视觉盲区能力\n- 插花任务：从执行器-物体互动扩展到物体-物体互动\n- 扫二维码任务：扫前后图像状态一致，暴露单帧模型记忆短板\n\n### Pi 0到Pi 0.5的跨越式进步\n\n- Pi 0在Table30上成功率仅20%多，平均4次尝试成功1次\n- Pi 0.5提升至42%左右，简单任务可做到100%成功\n- 国产千寻Spirit V1.5超越Pi 0.5登顶榜单\n- 从旁观者视角能明显感受到模型\"更灵光\"，行业处于具体进展阶段\n\n### 两种测评范式对比\n\n- RoboArena：Zero Shot设定，假设模型足够强可直接执行\n- RoboChallenge：Fine-tune设定，符合当前实际需求\n- 当前大多数模型在Zero Shot下成功率接近零，无法有效对比\n- 测评目标从\"百分之一精度\"转向\"反映模型发展趋势\"，能区分明显代差即可\n\n---\n\n## 二、具身智能的核心瓶颈：Scaling Data\n\n### 数据是当前最大瓶颈\n\n- 若有像大模型般无穷多的数据，具身模型技术路径已较清晰\n- 2026年具身智能最核心主题是\"Scaling Data\"\n- 瓶颈不在技术原理，而在规模化、低成本获取有效数据\n\n### 四种数据获取路径\n\n- **仿真数据**：需艺术家在仿真器中搭建场景，扩展缓慢，多样性难以提升\n- **人类视频数据**：从人类操作视频中学习，效率高\n- **可穿戴设备采集**：工作者佩戴设备采集真实场景，可达千万小时级别\n- **遥操作数据**：真机远程操作，质量最高但成本高（需建造机器人）\n\n### 数据路径的战略选择\n\n- 千寻选择：人类视频 + 可穿戴 + 遥操作，排除仿真\n- 原力灵机选择：以真机为主，复用旷视时期的大规模线下采集体系经验\n- Generalist AI策略：人拿夹子采集，已采27万小时，每周新增1万小时\n- 条条大路通罗马，最终卡点可能相同\n\n### 仿真数据的困境\n\n- 每个仿真场景需人工搭建，耗时缓慢\n- 需持续投入3D资产制作、大规模资产扫描\n- 当前多样性提升存在瓶颈，但未来可能成为重要方向\n\n---\n\n## 三、VLA模型的记忆缺失问题\n\n### 单帧模型的失忆困境\n\n- 大多数开源VLA基于单帧，无记忆能力\n- 模型每0.几秒就\"失忆\"，类似\"每7秒就忘\"的金鱼\n- 只能看到当前场景，无法记住之前执行的动作\n\n### 记忆短板的实战暴露\n\n- 扫二维码任务：拿起扫码枪扫前扫后图像状态一致\n- 模型无法判断是否已扫码，常常一伸手后停止不动\n- 需记忆能力支持：模型需记住\"刚才干了什么\"\n\n### 下一个关键突破点\n\n- 记忆能力是VLA模型的必经之路\n- 部分研究已开始将记忆机制引入模型\n- 从单帧向多帧+记忆演进是技术趋势\n\n---\n\n## 四、具身智能的GPT-3时刻\n\n### 当前发展阶段\n\n- 类比大模型，具身智能处于\"视觉AlexNet时期\"\n- 历史是波波echo，且echo频率越来越快\n- 处于加速进化前夜\n\n### 标志性任务：叠被子\n\n- 扫地机器人厂商和家电厂不会认为叠被子是该做的事\n- 任务有一定用处且不那么简单\n- 旧技术（检测分割）无法完成，具身智能的突破口\n- Pi 0.6可叠纸盒，Dyna Robotics主攻叠毛巾等软物体操作\n\n### 时间的双重感知\n\n- 从业者看到早期信号的时间比普通人早得多\n- 普通人看到破圈需3-4年\n- 某些任务对从业者虽不惊艳但已表明临界点临近\n- 硬件精细度和给力程度是软物体操作的关键制约\n\n---\n\n## 五、Demo工程：行业公开的秘密\n\n### 四种造假方式\n\n- **Cherry pick**：录100遍取1条成功展示\n- **视频剪辑**：后期剪辑加速，掩盖实际耗时\n- **遥操作**：背后是人远程操作，非模型自主执行\n- **AIGC**：直接生成虚假演示视频\n\n### 防作弊机制\n\n- 放置iPad时钟防止剪辑加速\n- Demo时放置随机哈希值证明视频唯一性\n- 规则取最后一次提交成绩，防止多次提交取最优\n- 在线测评环境下无法控制物理环境，作弊成本上升\n\n### 唯一可靠验证方法\n\n- 现场观摩是辨别demo真伪的唯一去处\n- 任何视频都可能被精心制作\n- 行业对\"demo工程\"心照不宣但很少公开讨论\n\n---\n\n## 六、2026年中美具身竞争格局\n\n### 中国能否实现具身DeepSeek时刻\n\n- 过去看国外工作如Google只能羡慕\n- 视觉时代人脸识别：Google从\"天外来物\"到国内追上仅用3年\n- 当前节奏更快，具身领域可能更快实现追赶\n- 2026年可能见证中国在具身领域超越美国\n\n### 自信度随技术路线清晰化提升\n\n- 创业初期需不断说服自己\"时刻已到\"\n- 随着技术路线收敛，疑惑变少，确定性增加\n- 2026年核心悬念：具身基础模型能否达到GPT-3或GPT-3.5水平\n- 行业进步具体可见，信心建立在实测数据而非demo视频\n\n---\n\n## 核心术语\n\n- **VLA**：Vision-Language-Action模型，具身智能主流技术路线\n- **Fine-tune**：使用少量示范数据对基础模型进行微调\n- **Zero Shot**：零样本，无需示例数据直接执行任务\n- **Cherry pick**：从多次尝试中挑选最成功的展示\n- **Table30**：RoboChallenge的30个桌面操作任务\n- **RoboChallenge**：原力灵机与Hugging Face发起的Fine-tune测评平台\n- **RoboArena**：Physical Intelligence发起的Zero Shot测评平台\n- **Pi**：Physical Intelligence的具身模型系列\n- **Demo工程**：精心挑选、剪辑、优化的演示视频\n",
    "createdAt": "2026-02-04T04:18:00Z",
    "updatedAt": "2026-02-04T05:11:12Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "podcast"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/8",
    "commentsCount": 0,
    "excerpt": "访谈来源：晚点聊 LateTalk 第149期 嘉宾：范浩强（原力灵机联创）、高阳（千寻智能联创兼首席科学家） ---  一、具身智能测评：从Demo工程到科学评测  RoboChallenge平台设计理念 - Robotics研究长期依赖cherry-pick的demo视频，录100遍取1条成功展..."
  },
  {
    "id": 3870737295,
    "number": 7,
    "title": "Demystifying evals for AI agents",
    "content": "# Demystifying evals for AI agents\n\n**来源**: [Demystifying evals for AI agents](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents) | Anthropic Engineering\n\n---\n\n## 评估体系的核心概念\n\n- **评估(Eval)**：给AI输入，应用评分逻辑测量输出的测试系统\n- **单轮评估**：一次提示、一次响应、一次评分—适用于早期LLM测试\n- **多轮评估**：Agent跨越多个轮次调用工具、修改状态、适应中间结果\n- **Task（任务）**：具有定义输入和成功标准的单个测试用例\n- **Trial（试验）**：对任务的单次尝试—多次试验产生更一致的结果\n- **Grader（评分器）**：对Agent性能某方面进行评分的逻辑\n- **Transcript（记录）**：试验的完整记录—包含输出、工具调用、推理、中间结果\n- **Outcome（结果）**：试验结束时环境的最终状态—区别于Agent声称的状态\n- **Evaluation Harness**：端到端运行评估的基础设施\n- **Agent Harness**：使模型能够作为Agent运行的系统（如Claude Code）\n- **Evaluation Suite**：为测量特定能力而设计的任务集合\n\n**关键洞察**：Agent评估的核心复杂性来自多轮交互—错误会传播和累积，且前沿模型可能找到超越静态评估限制的创造性解决方案\n\n---\n\n## 构建评估的时机与价值\n\n- **早期构建**：在原型阶段即可开始，20-50个简单任务即可起步\n- **效应量原理**：早期Agent开发的每个系统变更都有明显影响，小样本量足够检测\n- **明确成功定义**：评估迫使产品团队明确定义Agent的成功标准\n- **避免反应式循环**：无评估时团队陷入\"等待投诉→手动重现→修复→祈祷无回归\"的循环\n- **加速模型采用**：有评估的团队可在数天内确定新模型优势并升级，无评估团队需数周测试\n- **免费获得基线**：一旦建立评估，自动获得延迟、Token使用、每任务成本、错误率的跟踪基准\n- **产品-研究沟通**：评估成为产品与研究团队之间最高带宽的沟通渠道\n\n**关键洞察**：评估的价值随时间复合—成本前期可见，收益后期累积，容易被低估\n\n---\n\n## 评分器类型与选择框架\n\n### 代码评分器\n- **适用场景**：确定性测试、单元测试、静态分析、状态验证\n- **优势**：快速、廉价、客观、可重现、易于调试\n- **局限**：对不符合精确模式的有效变体脆弱、缺乏细微差别\n- **方法**：字符串匹配（精确/正则/模糊）、二元测试、Lint/类型/安全检查\n\n### 模型评分器\n- **适用场景**：开放式任务、自由形式输出、需要细微差别的判断\n- **优势**：灵活、可扩展、捕捉细微差别、处理开放性输出\n- **局限**：非确定性、比代码昂贵、需要与人工评分器校准\n- **方法**：基于量表的评分、自然语言断言、成对比较、参考基准评估、多评委共识\n\n### 人工评分器\n- **适用场景**：校准模型评分器、主观性强的任务、最终质量验证\n- **优势**：金标准质量、匹配专家用户判断\n- **局限**：昂贵、缓慢、需要大规模专家访问\n- **方法**：SME审查、众包判断、抽样检查、A/B测试\n\n**选择原则**：代码评分器优先→模型评分器补充→人工评分器校准\n\n---\n\n## 不同Agent类型的评估策略\n\n### 编程Agent\n- **核心方法**：确定性测试为主—单元测试通过即成功\n- **SWE-Bench Verified**：从GitHub仓库获取issue，通过运行测试套件评分\n- **Terminal-Bench**：测试端到端技术任务（如从源码构建Linux内核）\n- **评分维度**：测试通过性+代码质量规则+工具调用行为\n- **关键实践**：稳定测试环境+完善测试用例+生成代码的静态分析\n\n### 对话Agent\n- **核心挑战**：交互质量本身是评估对象\n- **多维成功**：工单解决（状态检查）+<10轮对话（记录约束）+语气适当（LLM量表）\n- **τ-Bench/τ²-Bench**：模拟多轮交互—一个模型扮演用户角色\n- **评分方法**：LLM量表评估任务完成+交互质量+第二LLM模拟用户\n- **注意**：许多任务有多种\"正确\"解决方案，避免刚性路径评分\n\n### 研究Agent\n- **核心挑战**：质量只能相对于任务判断—\"全面\"、\"有据\"、\"正确\"标准因场景而异\n- **评分组合**：基础性检查（声明有来源支持）+覆盖检查（必须包含的关键事实）+来源质量检查\n- **BrowseComp**：测试Agent能否在开放网络中找到\"大海捞针\"式答案\n- **关键实践**：LLM量表需频繁与专家人工判断校准\n- **客观答案**：对有客观正确答案的任务使用精确匹配\n\n### 计算机使用Agent\n- **评估环境**：真实或沙箱环境中运行Agent，检查是否达到预期结果\n- **WebArena**：基于浏览器的任务—URL和页面状态检查+后端状态验证\n- **OSWorld**：完整操作系统控制—检查文件系统状态、应用配置、数据库内容、UI元素属性\n- **效率权衡**：DOM交互快但Token密集，截图交互慢但Token高效\n- **实践案例**：Claude for Chrome开发评估检查Agent是否选择正确工具\n\n---\n\n## 非确定性评估的度量指标\n\n- **pass@k**：k次尝试中至少一次成功的概率\n  - k增加时pass@k上升—更多射门机会提高至少一次成功几率\n  - 适用场景：工具类Agent，一次成功即有价值\n- **pass^k**：所有k次试验都成功的概率\n  - k增加时pass^k下降—要求更多次一致成功是更高门槛\n  - 计算：单次75%成功率，3次试验全部成功概率=0.75³≈42%\n  - 适用场景：面向客户的Agent，用户期望每次都可靠\n- **指标选择**：根据产品需求选择—pass@k用于一次成功重要，pass^k用于一致性关键\n\n**关键洞察**：k=1时两者相同（等于单次成功率）；k=10时两者讲述相反故事—pass@k接近100%而pass^k趋近0%\n\n---\n\n## 从零到一的评估构建路线图\n\n### 收集初始任务\n1. **从20-50个简单任务开始**—团队误以为需要数百个任务而延迟构建\n2. **已有手动检查优先**：开发中手动验证的行为+最终用户尝试的常见任务\n3. **从失败收集**：生产环境中查看Bug跟踪器和支持队列，将用户报告的失败转为测试用例\n4. **明确任务规格**：两个领域专家应能独立达成相同通过/失败判断\n5. **创建参考解决方案**：证明任务可解+验证评分器正确配置\n\n### 构建平衡问题集\n- **双向测试**：同时测试行为应该发生和不应该发生的场景\n- **避免类别不平衡**：单向评估导致单向优化\n- **实战案例**：Claude.ai网络搜索评估—应搜索查询（如天气）+不应搜索查询（如\"谁创立了Apple\"）\n- **避免模糊规格**：评分器检查的所有内容应从任务描述中清晰可见\n\n### 设计评估Harness与评分器\n- **环境隔离**：每次试验从干净环境开始—避免共享状态导致的相关失败\n- **生产一致性**：评估中的Agent功能应与生产环境中的Agent大致相同\n- **评分稳定**：环境本身不应引入额外噪声\n- **优先结果评分**：评估Agent产出了什么，而非采取的路径—Agent经常找到评估设计者未预期的有效方法\n- **部分信用**：对多组件任务建立部分信用机制\n- **LLM校准**：LLM评委应与专家人工判断密切校准\n\n### 长期维护与使用\n- **阅读记录**：投资工具查看评估记录，定期阅读以验证评分器工作良好\n- **公平失败**：失败应显得公平—清楚Agent哪里出错及为何出错\n- **监控饱和**：100%通过率的评估只跟踪回归，不提供改进信号\n- **持续迭代**：评估套件是需要持续关注的活体工件\n- **领域专家贡献**：最接近产品要求和用户的人最适合定义成功\n\n---\n\n## 评估与其他方法的协同\n\n| 方法 | 最佳使用阶段 | 核心价值 |\n|------|-------------|----------|\n| **自动化评估** | 发布前/CI/CD | 无用户影响快速迭代、每次提交运行、大规模测试场景 |\n| **生产监控** | 发布后 | 揭示真实用户行为、捕捉合成评估遗漏的问题 |\n| **A/B测试** | 有足够流量时 | 衡量真实用户结果（留存、任务完成）、控制混杂因素 |\n| **用户反馈** | 持续 | 揭示未预期问题、附带真实用户案例 |\n| **手动记录审查** | 持续 | 建立失败模式直觉、捕捉自动化检查遗漏的微妙质量问题 |\n| **系统性人工研究** | 校准阶段 | LLM评分器校准、主观输出评估 |\n\n**瑞士奶酪模型**：没有单一评估层能捕获所有问题，多层结合使通过一层的失败被另一层捕获\n\n---\n\n## 评估框架选择\n\n- **Harbor**：容器化环境运行Agent，跨云提供商大规模运行试验，标准化任务和评分器格式\n- **Promptfoo**：轻量灵活开源框架，声明式YAML配置，断言类型从字符串匹配到LLM量表\n- **Braintrust**：离线评估与生产可观测性结合的平台，autoevals库包含预建评分器\n- **LangSmith**：跟踪、离线/在线评估、数据集管理，与LangChain生态系统紧密集成\n- **Langfuse**：自托管开源替代方案，适合有数据驻留要求的团队\n\n**框架建议**：快速选择适合工作流程的框架，将精力投入迭代高质量测试用例和评分器\n\n---\n\n## 核心决策要点\n\n- **评估是核心组件而非事后补充**：投资早期开发加速，投资延迟导致反应式循环\n- **小样本起步**：20-50个简单任务足以开始，效应量原理支持早期小样本量\n- **明确成功标准**：评估是产品需求的压力测试，定义评估任务是验证要求是否足够具体的最佳方式\n- **阅读记录**：不阅读记录无法知道评分器是否工作良好，这是Agent开发的关键技能\n- **组合评分器**：代码评分器优先，模型评分器灵活补充，人工评分器校准\n- **评估驱动开发**：先构建评估定义计划能力，然后迭代直到Agent表现良好\n- **监控饱和**：接近饱和的评估需要扩展—高通过率的能力评估可\"毕业\"成为回归套件\n- **多方法验证**：自动化评估+生产监控+定期人工审查提供最完整的图景\n",
    "createdAt": "2026-01-29T13:37:52Z",
    "updatedAt": "2026-01-29T13:37:52Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "agent",
      "evaluation"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/7",
    "commentsCount": 0,
    "excerpt": "Demystifying evals for AI agents 来源: Demystifying evals for AI agents(https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents) | Anthro..."
  },
  {
    "id": 3863709777,
    "number": 6,
    "title": "印奇访谈 - 决策备忘录",
    "content": "# 印奇访谈决策备忘录\n\n---\n\n## 基础模型商业模式\n\n### 不可行的路径\n\n- 基模+纯2B不成立：年投入30-50亿，但2B变现周期长、收入上限有限\n- 基模+纯C端软件不成立：大厂拥有用户和数据飞轮，创业公司难以建立壁垒\n- ChatGPT非终极产品形态，交互仍不自然\n\n### 可行的路径\n\n- AI与终端（人车家）软硬结合是创业公司可行路径\n- 硬件市场难以垄断，多品牌共存给创业公司留出空间\n- 车是第一切口，机器人和穿戴设备是后续方向\n\n---\n\n## 战略取舍原则\n\n- AI 1.0最大教训：多线作战导致压强不够，应在\"想做、能做、可做\"三者交集处聚焦\n- 若重来，应16-17年all-in智驾，不打安防战场\n- 安防是2G市场，营销占比高，与纯技术团队基因不匹配\n- 上市不应成为目标，本质是业务-产品-利润的良性循环\n- 慢就是快：战略聚焦比快速扩张更重要\n\n---\n\n## 技术路径\n\n### 方向判断\n\n- AGI必须与物理世界交互，纯数字世界无法实现真正智能\n- 基模必须世界一流，否则后续无根基\n- 全模态（文字/语音/图像）是人机交互基础\n- VLA（Vision-Language-Action）是面向终端的差异化\n\n### 数据战略\n\n- 数据决定模型70-80%效果，数据汇报线应直连算法负责人\n- 数字空间与物理空间数据需融合于同一模型\n- 室内交互数据稀缺，物理数据收集需5-7年\n\n---\n\n## 组织与人才\n\n### 选人\n\n- 技术能力+协同能力+使命感+小ego，缺一不可\n- 做冷板凳能力是技术信仰的核心体现\n- 聪明人陷阱：想走捷径，但正确方式往往是笨办法\n\n### 架构\n\n- 数据、算法、系统工程三要素必须融合\n- 算法与系统同学交叉培养，不能割裂\n- AI组织需融合top-down（大项目资源集中）和bottom-up（创新活力）\n\n---\n\n## 竞争格局\n\n### 行业判断\n\n- 智驾将头部化为3-4家供应商，技术路径已清晰（模型驱动），窗口期约3年\n- 大模型竞赛赛程过半，进入淘汰赛\n- 过去10年最成功的AI公司是字节和特斯拉（从场景切入，非技术出发）\n\n### 应对策略\n\n- 创业公司需与巨头局部竞争，非全面对抗\n- 找到长板和切口，专注单一领域深耕\n",
    "createdAt": "2026-01-28T05:56:19Z",
    "updatedAt": "2026-01-28T05:57:11Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "podcast"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/6",
    "commentsCount": 0,
    "excerpt": "印奇访谈决策备忘录 ---  基础模型商业模式  不可行的路径 - 基模+纯2B不成立：年投入30-50亿，但2B变现周期长、收入上限有限 - 基模+纯C端软件不成立：大厂拥有用户和数据飞轮，创业公司难以建立壁垒 - ChatGPT非终极产品形态，交互仍不自然  可行的路径 - AI与终端（人车家）..."
  },
  {
    "id": 3856467944,
    "number": 5,
    "title": "张月光访谈 - 决策备忘录",
    "content": "# 张月光访谈 - 决策备忘录\n\n## 一、创业动机\n\n### 两个最好的创业理由\n\n- 期望收益率最高的两个创业理由：1) 就想当老板（不想打工）——第一天就成功了；2) 特别想让某件事发生（别人做成了也不算输）\n- 想发财或想证明自己的期望收益都比较差\n\n### 本次创业的动机\n\n- 做一个能突破能力边界的AI朋友\n- 不是只提供情绪价值，而是提供实用价值；从PPT开始，逐步扩展到更多能力\n\n### 探索期策略\n\n- 在迷茫期用最小成本探索，不 All in直到找到笃信的方向\n- 在没确定之前不会All in，把成本控制到最低水平\n- 如果不知道就不要着急，着急会带来更多损耗\n\n---\n\n## 二、大厂内部的两种游戏\n\n### 外部游戏 vs 内部游戏\n\n- 外部游戏是通过打赢外部敌人来升级；内部游戏是打赢身边人就能升级\n- 内部游戏会让绝大部分人变成向内作战的人，这是大厂里很难克服的\"地心引力\"\n- 没有增量时很难避免内部游戏；外部游戏需要周期支持（12-16年是黄金周期，18-19年是真空期）\n- AI的诞生又提供了外部游戏的机会——增量市场重新打开\n\n---\n\n## 三、妙鸭产品决策\n\n### 妙鸭不是 AI Native 产品\n\n- AI Native 需要：没有这代AI就做不了（必要条件）+ 用户输入/输出的开放性（充分条件）\n- 妙鸭通过限制用户自由度来谋求更稳定的效果\n- 这本质上是典型的互联网产品思维\n\n### 三个关键决策\n\n- 技术选择：当时只有图像技术相对成熟\n- 垂直细分：作为后发团队，选择\"写实人像\"这个垂直方向\n- 商业模式：选择ToC端到端定价的写真生意，而非ToB的电商图生产——电商是很长的商业链条，不是核心环节就没有溢价权\n\n### \"真像美\"三原则\n\n- 真（看不出来是AI做的）+ 像（跟用户足够像）+ 美（比真实自己好看一点）\n- \"真\"是关键——能卖过去价值就会被无限放大，卖不过去价值会有很低的上限\n- \"像\"满足了用户最爱传播的三类内容：与我有关、对我有用、喜闻乐见\n\n### 产品定位本质\n\n- 妙鸭是新消费品牌而非图像产品，与海马体一桌，与美图不是一桌\n- 产品文案中没有任何地方用到\"AI\"这个词\n- 写真生意和图像工具是两个赛道，不是自然延伸关系\n\n### 妙鸭的技术架构：\"三模型\"策略\n\n- 用一个模型同时实现\"真像美\"在当时技术下几乎不可能，解法是三个专家模型串联\n- 三个专家模型各司其职——模型1负责\"真\"（用普通人照片训练，保留瑕疵），模型2负责\"像\"（人脸ID控制），模型3负责\"美\"（模板风格）\n- 通过完全固定工程链路、将用户自由度降为零，换取效果的确定性\n- 这是互联网产品思维——限制自由度以换取稳定输出，而非真正的AI Native开放范式\n\n---\n\n## 四、互联网产品 vs AI Native 产品\n\n### 范式变化：从流程设计到上下文设计\n\n- 互联网产品是\"面向流程\"的设计，AI Native产品是\"面向上下文\"的设计\n- 互联网产品设计路线和决策树，用户拥有有限自由度；AI Native产品的用户输入输出都非常开放，无法穷举所有行为可能\n- 最关键的设计问题变成：用户需要给模型什么上下文？什么是最佳的context和prompt实践？\n- 传统UI/UX思维需要升级为AI Native的context设计思维\n\n### 组织协同方式需要变化\n\n- 传统互联网产品是线性协同（产品定义→设计师画图→工程师开发），但AI Native产品需要两段式混合摸索\n- AI Native 需要：1) 先对模型部分进行混合摸索（角色边界模糊）；2) 等清楚之后再分工，产品经理设计流程去获取用户的context\n- 如果用老方式做AI产品，会出现\"设计完了发现效果不是这样\"的问题\n\n### AI Native的机会窗口\n\n- 如果AI组织和互联网组织完全一样，理论上没有太多机会留给新玩家\n- 大厂在算力、数据、人才上具有压倒性优势，\"大厂难掉头、反应慢\"是幻想\n- 传统互联网公司的线性工作方式（产品→设计→开发）难以适应AI Native的混合探索模式\n- 新玩家若能建立\"不同的物种\"——组织方式上的代差——可能带来突围机会\n\n---\n\n## 五、\"单向门\"产品方法论\n\n### 什么是单向门产品\n\n- 用了之后知道再也不会用以前的解决方案了（如Cursor/Claude Code之于IDE）\n- 这种产品可以慢慢做、长期做，是足够长期正确的事情\n- 市场份额会一点点往上涨，最终会被充分放大\n\n### 单向门 = 为旧需求提供新解法\n\n- 创新不是创造新需求，而是为一个旧需求提供新解法\n- 这个新解法比起旧解法是全方位优势的\n- 哪怕今天做不到全面优势，但能看到未来它会成为全面优势\n- 最大的机会在于看到一个别人都还没看到的单向门\n\n---\n\n## 六、AI产品洞察\n\n### 90分等于0分\n\n- AI产品必须迈过某个可用性门槛，没迈过之前即使90分也等于0分\n- AI生图在\"一眼看出是AI\"和\"看不出是AI\"之间存在非线性的价值跃迁\n- 妙鸭迈过了那条线——没有人能看出这是AI做的，这时成本的巨大优势才显现出来\n- 今天很多AI产品还停留在90分阶段，未迈过可用性门槛，商业价值被严重高估\n\n### 效果优先于交互\n\n- 做Agent产品时，效果比交互设计更重要\n- 一开始设计了很好的交互，但模型效果特别差，产品完全不可用\n- 不管产品交互长什么样，先打磨最小生成单元；先调效果，等效果明白了，再设计流程去获取必要的context\n- AI Native产品的开发顺序与传统互联网相反——先验证模型能力边界，再设计产品流程\n\n---\n\n## 七、AI陪伴赛道\n\n### 游戏化解决方案\n\n- 用游戏的方式可以解决AI陪伴的三个行业通病：用户门槛过高、商业化效果差、角色无法成长\n- UGC转PGC降低用户门槛\n- 游戏自带商业模式\n- PGC角色可以不断成长\n\n### AI乙女游戏与传统乙女游戏的区别\n\n- AI乙女游戏创造的是以互动性为优先的IP，传统乙女游戏创造的是以表现为核心的IP\n- 任何IP都有四个要素：价值观、视觉包装、作品表达、用户交互\n- 越贵的IP越要降低交互频次（大明星不上直播）\n- AI带来的是可以创造以互动性为优先的IP\n- 传统乙女游戏公司不可能在自己的游戏里把人物做成可以AI聊天，会破坏人设\n\n---\n\n## 八、平台与媒体\n\n### 平台诞生的条件\n\n- 新平台的机会只来自于新媒介+新交互的组合\n- ChatGPT本身就是一种新媒介形式（对话交互）\n- Zora还是短视频，没有新媒介也没有新交互，不可能成为新抖音\n\n### 信息媒介的演进\n\n- 人类经历了文字→图片→短视频三代主流信息媒介的迭代\n- 如果是媒介迭代，就不会只用来做内容娱乐\n- 所有东西都会升级（教育、电商等）\n\n### AI与内容的结合\n\n- AI与内容的结合是一个在合适价格下慢慢做可能会很大的东西\n- 过去几年冒出来的很多好公司都是内容性公司（米哈游、游戏科学、追光动画、泡泡玛特等）\n- 平台性的东西在互联网20年周期做完了\n- 好内容变得稀缺起来\n\n---\n\n## 九、AI时代的人才与组织\n\n### 技能贬值化\n\n- 今天的技能正在贬值化，人和AI的关系变成\"人负责will（意图意志），AI负责skill\"\n- 上一时代的专业技能（熟练的、别人不具备的）正在被AI快速复制和超越\n- 多元化品位以及博学的程度正在决定团队的核心竞争力，广度比深度更重要\n- 招聘时需重新评估\"技能熟练度\"的权重，增加对\"审美品位、跨界整合能力\"的考量\n\n### 团队多样性\n\n- AI时代比上个时代更加需要团队的多样性\n- 大厂的人：规范性使命必达，执行时的坚决度有保障\n- 独立开发者：灵活性强，更年轻、更 native，多面手（又要开发又要设计又要产品）\n- 创业公司的人：品位非常好（审美品位、产品品位、营销品位）\n- 不同做事风格的人要混合在一起\n\n### 组织方式必须变化\n\n- 传统互联网的线性协同不适用于AI Native产品\n- AI Native产品的组织需要两段式：1) 先对模型部分进行混合摸索（角色边界模糊，产品/设计/技术一起搞清楚）；2) 等清楚之后再分工，产品经理设计流程去获取用户的context\n- 如果用老方式做AI产品，会出现\"设计完了发现效果不是这样\"的问题\n- 这是新玩家相对于大厂的组织代差机会\n",
    "createdAt": "2026-01-26T15:32:53Z",
    "updatedAt": "2026-01-26T15:33:33Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "podcast"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/5",
    "commentsCount": 0,
    "excerpt": "张月光访谈 - 决策备忘录  一、创业动机  两个最好的创业理由 - 期望收益率最高的两个创业理由：1) 就想当老板（不想打工）——第一天就成功了；2) 特别想让某件事发生（别人做成了也不算输） - 想发财或想证明自己的期望收益都比较差  本次创业的动机 - 做一个能突破能力边界的AI朋友 - 不是..."
  },
  {
    "id": 3846513583,
    "number": 4,
    "title": "OpenAI的卖铲人：一套围绕Infra、迭代速度与组织信息流的叙事",
    "content": "# OpenAI的卖铲人：一套围绕Infra、迭代速度与组织信息流的叙事\n\n最近看完了对翁家翌的采访，访谈的表达的核心不在“提出某个天才算法”，而在“让所有算法能被稳定、快速、反复验证”。在大模型时代，很多结果更像是工程系统的产物：正确的基础设施 + 足够密集的迭代次数，把胜率堆出来。\n\n---\n\n## 1）一个位置：RL Infra\n\nJiayi的定位是 OpenAI 的 RL 基础设施，覆盖从 GPT-3.5 到 GPT-5 的多个 release。这个位置的特点不是“更底层”，而是“更靠近结果交付”：RL 是每个模型都要走的一段路，所以基础设施会频繁出现在每次 release 的关键路径上。\n\n“卖铲子”的含义在这里更像是：\n\n* 不是亲自去挖每一座金矿，而是把挖矿的工具做成“所有人都必须用”的形态\n* 工作成果不体现为某一个 paper 的结论，而体现为“别人每一次实验都更快、更少踩坑”\n\n---\n\n## 2）工程能力 vs 算法创新：争的是“单位时间内能验证多少次”\n\n> “教一个 researcher 如何做好 engineering，要远比教一个 engineer 如何做好 research 来得难。”\n\n* research lab 的探索首先依赖 **infra 的正确性**\n* 如果 infra 正确，差异主要来自 **单位时间迭代次数**\n* “idea 很便宜”，真正昂贵的是把 idea 变成一次可信的验证\n* 现实层面，很多差距来自 bug：谁修得多、修得快，谁的训练就更接近“理论上该有的样子”\n\n这套逻辑把“模型强不强”从玄学拉回到可归因的系统问题：吞吐、正确性、反馈周期、迭代速度。\n\n---\n\n## 3）从 Toy 到 工业级：RL 的瓶颈被彻底换了位置\n\n一个有意思的对比是：在传统 RL（Atari、MuJoCo 之类）里，环境复杂、采样相对便宜；到了 LLM 的 RL post-training，环境反而很“简单”（文本提示），但采样与训练成本变得昂贵，瓶颈转到系统侧：推理吞吐、分布式训练、采样效率、端到端 pipeline。\n\n这里也解释了为什么“学校里很难学到同等难度的东西”：\n\n* 需要跨 RL、ML Sys、大模型推理、分布式训练的交叉语境\n* 很多问题不是“多招几个人”能解决，而是需要深上下文才能定位与收敛\n\n---\n\n## 4）组织的核心变量：信息流通是否“无损”\n\nOpenAI 的组织变化被描述成从“大号实验室”走向工业化：人数从几百扩到三千级别，人才密度难维持，但可以用小团队结构维持创新。真正难的是：决策与执行之间的信息传递是否一致。\n\n访谈里有个很形象的类比：\n“管公司和管代码库一样”，关键在 consistency；如果不一致，就像“上身动了脚没动”。\n\n当组织规模扩大，沟通成本、上下文断裂、系统臃肿会自然出现。对于训练 infra 这种“牵一发而动全身”的系统，信息流一旦失真，最终会表现为：\n\n* pipeline 复杂度上升\n* bug 与技术债堆积\n* 迭代速度下降\n  这些都不是抽象管理问题，而是直接反映在训练曲线和交付节奏里。\n\n---\n\n## 5）ChatGPT 的“意外成功”：不是 all-in 的神话\n\n访谈给出的细节很反常识：ChatGPT 发布前并没有预设“爆款叙事”，更像一次收集真实用户数据的尝试，预期用户规模很小，没人用就关。实际是指数级增长、服务器被反复打爆。\n\n另一个细节是团队规模并不大：贡献者名单大概十来人级别。这强化了一个事实，当产品形态对了，外部扩散速度可以远远超过内部规划。\n\n---\n\n## 6）评价体系与路径选择：把“指标”换成可控的东西\n\n访谈里出现了一个很早的定义：\n\n> “人生游戏的结算分数 = 记得你名字的人数。”\n\n它对应的做法不是鸡汤，而是更像“指标工程”：论文、比赛、GitHub stars被当作可量化的替代指标；GPA 则被降级成“够用就行”的约束条件。\n\n关于 PhD vs Master 的判断也非常尖锐：\n\n> “如果你想进工业界，读 PhD 就是浪费生命。”\n\n放在这期访谈的主线里，这句话更像是在强调：\n当目标函数是工业界的真实系统问题时，学历本身并不构成优势，优势来自经验与语境匹配——尤其是 infra 这类“越做越像手艺活”的工作。\n\n---\n\n## 7）开源作为“慈善”：从需求出发，而不是从技术出发\n\nJiayi做的两个开源项目被反复提及：Tianshou与Tuixue。共性很明确：\n\n* 来自真实的个人需求\n* 市面上没有顺手工具，就自己造\n* 造完开源，影响力自然扩散\n  甚至把“代码工具”描述为一种慈善式的分享：追求 impact，哪怕不赚钱也成立。\n\n这种叙事很少谈“技术有多复杂”，更多谈“抓住需求”。技术在这里退居二线，产品/使用场景变成第一性因素。\n\n---\n\n## 8）AGI、Agent 与“暂时的安全感”：问题在 deep context\n\n访谈里的 AGI 定义很个人化但也很可操作：\n\n> “AGI = 能够完成 80–90% 自己认为有意义的任务。”\n\n“为什么还没到”的解释同样是工程视角：\n\n* 某些工作场景极度 out-of-distribution（例如直接改 infra 代码）\n* 验证反馈周期太长、成本太高\n* deep context 缺失使得“看起来能写代码”与“能在真实系统里安全落地”之间差距巨大\n\n关于 Agent，也被放在 RL 的框架下理解：本质仍是 post-train 的同类问题，只是环境与步骤更复杂一些。\n\n---\n\n## 9）一个尾注：确定性世界观与“忘掉它”的策略\n\n访谈后半段转向个人哲学，最极端的一句是：\n\n> “我们生活在一个确定性的马尔可夫过程里。”\n\n但它没有落到虚无，而落到一种实用主义的应对：\n把它当成不可证明也不可证伪的背景噪音，最有效的策略是“忘掉这一切”，继续体验当下。\n\n---\n\n## 结尾：这期访谈真正反复出现的关键词\n\n把整期访谈压缩成几个高频变量，会发现它很少在讨论“某个神奇技巧”，而是在讨论一条更稳定的因果链：\n**正确的基础设施 → 更短的反馈周期 → 更高的迭代次数 → 更接近可交付的性能**。\n",
    "createdAt": "2026-01-23T08:55:23Z",
    "updatedAt": "2026-01-23T09:13:16Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "podcast"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/4",
    "commentsCount": 0,
    "excerpt": "OpenAI的卖铲人：一套围绕Infra、迭代速度与组织信息流的叙事 最近看完了对翁家翌的采访，访谈的表达的核心不在“提出某个天才算法”，而在“让所有算法能被稳定、快速、反复验证”。在大模型时代，很多结果更像是工程系统的产物：正确的基础设施 + 足够密集的迭代次数，把胜率堆出来。 ---  1）一个..."
  },
  {
    "id": 3800808182,
    "number": 3,
    "title": "Polymarket 其实是“定价游戏”",
    "content": "# Polymarket 其实是“定价游戏”\n\n**一个观察：Polymarket 不是\"谁判断对了未来\"，而是\"谁把现实更快定价进价格\"。在\"预测题\"里待久了，交学费是大概率的事。**\n\nPolymarket 上存在三层逻辑：**它是什么 → 怎么看盘 → 优势在哪**。每层对应不同的认知阶段，也对应不同的玩法。\n\n---\n\n## 1. Binary Contract：游戏规则的起点\n\n策略之前，先搞清楚这个市场的底层结构。这不是理论推演，而是几次亏钱后得到的教训。\n\n### 1.1 数学结构\n\nPolymarket 的每个市场本质上是一个 **Binary Contract**：\n\n| 合约 | 条件 | 结算 |\n|-----|------|-----|\n| YES | 结果为真 | $1 |\n| NO | 结果为假 | $1 |\n\n当价格显示 $0.62 时，意思是市场认为这件事有 62% 的概率会发生。从合约角度看，这更像是用 62 美分买一张\"可能兑付 1 美元\"的期权。\n\n这带来一个视角转变：\n\n```\n问\"会发生什么\" → Probability Assessment\n问\"什么已经发生但价格还没反映\" → Pricing Inefficiency\n```\n\n### 1.2 \"预测\"思维的陷阱\n\n一种常见误解是把 Polymarket 当成\"未来的投票机\"——根据判断下注，等待结果揭晓。这种方式的问题在于：\n\n**赚的不是\"对错\"，而是\"价格更新过程中的滞后\"。**\n\n市场的运转路径大致是：\n\n```\nReal-world Event → Information Diffusion → Price Update → Arbitrageurs Enter → Price Convergence\n```\n\n利润来源通常在这几个环节：\n- 信息传播速度差带来的时间窗口\n- 参与者情绪化导致的价格偏离\n- Resolution Criteria 与事实之间的时间差\n\n---\n\n## 2. 盘口分析：实际看什么\n\n接受 Polymarket 是真实市场而非预测游戏后，看盘方式需要调整。三个核心指标如下。\n\n### 2.1 Liquidity\n\nLiquidity 决定进出的成本。简单理解就是：\n\n**能不能进得去、出得来，并且不把价格搞崩。**\n\nLiquidity 不足时通常会出现两种情况：\n- 进场时买入行为推高价格，实际成交价（Fill Price）高于盘面显示价格（Market Price）\n- 退出时盘口没有足够对手方，被迫以更差价格成交\n\n常用的 Liquidity 指标：\n- **Order Book Depth**：当前价格附近各档位的订单总量\n- **24h Trading Volume**：历史活跃度的一个参考\n- **Maker/Taker Ratio**：做市商参与程度的信号\n\n### 2.2 Spread\n\nSpread 是买一价和卖一价之间的差距，本质是\"不耐心\"要付出的成本。\n\n```python\nBid-Ask Spread = Ask Price - Bid Price\n```\n\n一个典型场景：\n- YES 显示价格 $0.62\n- 实际 Bid Price 可能 $0.60，Ask Price $0.65\n- 如果立即买入并卖出（不考虑手续费），已经亏损 $0.05\n\n同样是这个方向这个判断，不同的 Execution 能力会带来完全不同的收益曲线。\n\n### 2.3 Resolution Time\n\n这个指标直接影响市场的\"性质\"：\n\n| Resolution Time | Market Characteristic |\n|----------------|----------------------|\n| Long (far from resolution) | Emotion-driven, similar to opinion voting |\n| Short (near resolution) | Pricing convergence, arbitrageurs dominate |\n\n一个观察：大部分可捕获的错价集中在\"信息已明朗但结算尚未触发\"的窗口期。这段时间利润最肥厚，竞争也最激烈。\n\n这三个指标看过之后，大概能判断这个市场有没有值得参与的空间。\n\n---\n\n## 3. 三种结构性机会\n\n观察发现，Polymarket 上存在几种相对可复制的错价来源。\n\n### 3.1 Temporal Arbitrage（临近结算错价）\n\n理论上，结算时间越近，价格应该越接近 $0 或 $1。但现实中经常能看到 $0.97~$0.99 还在交易。\n\n这种情况通常由以下因素导致：\n- 恐慌性出逃：持有者担心意外结果，提前平仓\n- Liquidity Gap：临近结算时做市商撤出\n- Slippage：大额订单把价格推离理论值\n\n这不是预测能力的问题，而是 Execution 能力的问题——在盘口很差的情况下完成正确成交。\n\n常见做法：\n- 用 **Limit Order** 而非 **Market Order**\n- 分批建仓，单次不冲击市场（minimize Market Impact）\n- 预设可接受的 Slippage 范围\n\n### 3.2 Pair Arbitrage（YES + NO 配对套利）\n\n这是最\"机械\"的一种方式，不需要主观判断方向。\n\n```python\navg_YES = total_cost_YES / quantity_YES\navg_NO  = total_cost_NO / quantity_NO\nPair Cost = avg_YES + avg_NO\n```\n\n当 Pair Cost < $1.00 时，无论最后哪边结算兑付 $1，都锁定利润。\n\n一个实际例子：\n- 买入 100 个 YES，平均成本 $0.60\n- 买入 100 个 NO，平均成本 $0.35\n- Pair Cost = $0.95\n- 锁定利润 = $0.05 × 100 = $5.00\n\n重点不在于判断方向，而在于持续扫描市场中出现的配对成本失衡。这种机会不定期出现，窗口通常很短。\n\n### 3.3 Cross-Market Arbitrage（跨市场逻辑约束）\n\n当多个市场之间存在逻辑关系时，价格有时会出现违反基本概率约束的情况。\n\n举例：\n- 市场A：候选人X赢得选举（概率 65%）\n- 市场B：候选人Y赢得选举（概率 40%）\n- 市场C：第一轮产生结果（概率 30%）\n\n如果 A + B 的概率之和 > 100%，或者 C 与 A/B 的组合逻辑矛盾，就存在套利空间。\n\n实现这种策略需要把市场间的逻辑关系写成约束条件，然后检测价格是否违背这些约束\n\n这种策略门槛较高，但一旦跑通，护城河相对较深。\n\n---\n\n## 4. 交易日志与复盘\n\n认知层面的内容如上。实践层面，有一些记录可供参考。\n\n### 4.1 日志字段\n\n记录每一笔交易，通常关注这些信息：\n\n| 字段 | 含义 |\n|-----|------|\n| Entry Price | 实际成交价 |\n| Position Size | 投入的资金量 |\n| Bid/Ask Snapshot | 入场时的盘口状态 |\n| Average Cost | 分批建仓的加权均价 |\n| Stop Loss | 预设的退出位置 |\n| Exit Price | 最终平仓价格 |\n| Exit Reason | 主动/被动/止损 |\n\n这些字段对应了前文提到的各个分析维度，方便事后归因。\n\n### 4.2 复盘流程\n\n每周花 30 分钟回顾交易日志，关注几个维度：\n\n|**Execution Analysis**\n|- Fill Price 与 Market Price 的差距（Slippage）\n|- 仓位是否影响了市场价格（Market Impact）\n\n|**Decision Analysis**\n|- 入场时的 Liquidity 是否足够\n|- Spread 在不在可接受范围\n|- 距离结算还有多少时间\n\n|**Attribution Analysis**\n|- 盈亏来自方向判断还是 Execution\n|- 如果亏损，是认知问题还是执行问题\n\n### 4.3 一个观察\n\nPolymarket 的特点：\n- 参与者情绪化\n- 信息传播不均匀\n- Resolution Criteria 与事实之间存在时间差\n\n规则与价格的间隙里，存在可捕获的收益。这不是\"预测谁对谁错\"的竞赛，而是\"谁能更快把 Pricing Inefficiency 装进口袋\"的效率竞争。\n\n---\n\n## 参考\n\n- [The Complete Polymarket Playbook (with real edges, visuals, and a learning path)](https://x.com/thejayden/status/2002716558464881081)\n- Polymarket: [What is Polymarket?](https://docs.polymarket.com/polymarket-learn/get-started/what-is-polymarket)\n\n****",
    "createdAt": "2026-01-11T06:14:13Z",
    "updatedAt": "2026-01-11T06:18:37Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "polymarket"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/3",
    "commentsCount": 0,
    "excerpt": "Polymarket 其实是“定价游戏” 一个观察：Polymarket 不是\"谁判断对了未来\"，而是\"谁把现实更快定价进价格\"。在\"预测题\"里待久了，交学费是大概率的事。 Polymarket 上存在三层逻辑：它是什么 → 怎么看盘 → 优势在哪。每层对应不同的认知阶段，也对应不同的玩法。 ---..."
  },
  {
    "id": 3800766965,
    "number": 2,
    "title": "扩散模型量化：如何在 ONNX 中优雅地处理「重复 N 步」问题",
    "content": "# 扩散模型量化：如何在 ONNX 中优雅地处理「重复 N 步」问题\n\n> 当你需要让 Stable Diffusion 在手机或边缘设备上跑起来时，一个关键问题摆在面前：扩散模型需要采样几十甚至上百步，到底该怎么量化？本文将从工程实践角度，帮你理清三种主流方案，并给出明确的选型建议。\n\n---\n\n## 问题的诞生\n\n以 Stable Diffusion 为代表的扩散模型，其核心是一个去噪网络（通常是 UNet）。在生成一张图的过程中，这个网络要被反复调用 N 次——每调用一次，就从噪声状态往前走一小步。\n\n这个看似简单的「重复 N 次」，在模型部署时却带来了一个让人头疼的问题：\n\n**应该把 UNet 在 ONNX 图里复制 N 份然后一次性跑完，还是只导出一份然后在运行时用 for 循环反复调用？**\n\n这个问题看似简单，背后却涉及模型大小、推理性能、工程维护成本等多个维度。今天我们就来深入剖析。\n\n---\n\n## 两种方案的抽象对比\n\n先让我们把问题抽象清楚，假设 N = 50 步：\n\n| 方案 | ONNX 图的结构 | 推理时的执行方式 |\n|------|--------------|-----------------|\n| **方案 A**：展开 N 份 | 把 UNet 拷贝 50 份，按时间步串联成一个大图 | 一次 `Session.run` 跑完整个图 |\n| **方案 B**：单步复用 | ONNX 里只有一份 UNet | 写个 for 循环，每次调用 `Session.run` 传新的 `x_t` |\n\n如果你正在考虑方案 A，先别急着动手——往下看。\n\n---\n\n## 方案 A：把模型展开 N 遍\n\n### 看起来很美，实则问题重重\n\n把模型展开 N 次，乍一看像是「一步到位」：不需要循环调用，减少了函数调用开销，多么优雅！\n\n但现实很骨感。\n\n**首先是模型体积爆炸。** 扩散模型本身就很大（UNet + VAE + Text Encoder），如果按 50 步展开，ONNX 文件大小直接乘以 50。加载时间、传输时间、磁盘占用都会成倍增加。更糟糕的是，过大的图会让可视化工具直接罢工，调试变成噩梦。\n\n**其次是维护成本极高。** 产品中经常需要调整采样步数：极速模式 10 步、质量模式 30 步、细节模式 50 步。一旦把 N 固死在图里，想改步数就得重新导出整套 ONNX + 重新量化。这运维成本，任谁都得掂量掂量。\n\n**最后是性能并不占优。** 很多人觉得减少 API 调用能提速，但现代推理引擎（ONNX Runtime、TensorRT、OpenVINO）对重复结构都有不错的融合和缓存优化，反而是图膨胀带来的缓存失效、调度开销可能抵消理论优势。在内存紧张的边缘设备上，这个问题尤为突出。\n\n> 所以，方案 A 一般只用于「一次性学术实验」或「对固定步数做极端 profiling」的场景，不推荐作为工程实践。\n\n---\n\n## 方案 B：单步量化 + 运行时循环\n\n### 当前业界的主流选择\n\n这正是当前 Stable Diffusion + ONNX Runtime 部署教程采用的方式：\n\n```\ntext_encoder.onnx  →  处理文本提示\nunet.onnx          →  单步去噪（量化后）\nvae_decoder.onnx   →  解码成最终图像\n```\n\n推理时在 Python/C# 中写采样循环，把 `x_t`（当前隐变量）和 `t`（当前时间步）一步步喂给量化后的 UNet。\n\n### 为什么这是更合理的选择\n\n**量化更简单。** 只需要对一个 UNet 做 PTQ/QAT，shape 推断更稳定，可以使用 ONNX Runtime 官方量化工具以及 AMD Quark、Intel Neural Compressor 等成熟工具链。\n\n**文件小，易部署。** ONNX 模型大小 ≈ 原 UNet 大小，适合移动端、边缘设备、Web 浏览器等资源受限场景。\n\n**灵活性最高。** 步数由外层 for 循环控制，随时可以调参，轻松支持 DDIM、DPM-Solver 等不同调度器，甚至可以实现自适应终止（early stopping）。\n\n**性能可以通过工程手段补足。** 使用 ONNX Runtime 的 IO Binding 避免重复内存拷贝，预热 session 消除首轮编译开销，在 GPU 上结合 CUDA Graph，循环开销大多可以摊平。\n\n### 一个隐藏的陷阱：量化误差累积\n\n但这里有个关键问题：扩散模型的量化误差会在多次去噪步骤中累积。早期步骤的小误差会沿着轨迹不断放大，导致最终图像质量下降。\n\n解决方案包括：\n\n- **多步感知校准**（如 AccuQuant）：校准时模拟真实的多步采样轨迹，而不只是单步激活分布。\n- **时间步感知修正**：为不同时间步设计不同的量化参数，在关键早期 timestep 更保守，后期更激进。\n\n这些都是基于「单步网络 + 循环调用」设计的，和方案 B 完全兼容。\n\n---\n\n## 方案 C：ONNX 图内显式循环（进阶最佳实践）\n\n### 用 Loop/Scan 算子封装循环\n\nONNX 标准提供了 `Loop` 和 `Scan` 运算符，用来在图内部表达循环。这是一种介于 A、B 之间，但综合优势更明显的做法。\n\n**结构特征：**\n\n- 图里只有一份「单步 UNet 子图」，但这份子图被作为 `Loop` 的 body 反复执行 N 次；\n- 步数 N 可以是常量（图中写死，类似 A 但不复制结构），也可以是输入张量（运行时指定，实现动态步数）。\n\n**核心优势：**\n\n1. **保持模型紧凑**——不发生 N 倍结构复制，文件大小和方案 B 类似。\n2. **减少框架层调度开销**——循环在 ONNX Runtime 内部执行，相比「外层 Python for + 内层 Session.run」，调用边界更少，内存复用和算子调度优化更容易做。\n3. **更利于高端推理后端优化**——对 TensorRT、QNN、OpenVINO 等运行时，图内 Loop 可能被特殊对待，如展开少量迭代做 kernel fusion，或对循环体进行更强的运算图优化。\n4. **仍具备灵活性**——可以通过输入控制步数，仍然是单一量化子网络。\n\n**什么时候不必用 Loop：**\n\n- 如果部署环境不支持 ONNX Loop 或支持不佳；\n- 或者你的工程栈已经在 C++/Rust 侧对 for 循环做了充分优化（IO Binding + CUDA Graph）。\n\n\n### 参考文献\n\n[1] [Quantize ONNX models - ONNX Runtime](https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html)  \n[2] [Inference Stable Diffusion with C# and ONNX Runtime](https://onnxruntime.ai/docs/tutorials/csharp/stable-diffusion-csharp.html)  \n[3] [How to Run Stable Diffusion with ONNX](https://towardsdatascience.com/how-to-run-stable-diffusion-with-onnx-dafd2d29cd14/)  \n[4] [Quantizing a Diffusion Model using Quark - AMD](https://quark.docs.amd.com/latest/tutorials/torch/diffusion_tutorial/diffusion_tutorial.html)  \n[5] [ONNX Models Repository](https://github.com/onnx/models)  \n[6] [AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models](https://arxiv.org/abs/2510.20348)  \n[7] [Timestep-Aware Correction for Quantized Diffusion Models](https://arxiv.org/abs/2407.03917)  \n[8] [Q-Diffusion: Quantizing Diffusion Models - ICCV 2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Q-Diffusion_Quantizing_Diffusion_Models_ICCV_2023_paper.pdf)  \n[9] [Error Propagation Mechanisms and Compensation for Quantized Diffusion Models](https://arxiv.org/html/2508.12094v3)  \n[10] [Loop - ONNX Operator Documentation](https://onnx.ai/onnx/operators/onnx__Loop.html)  \n[11] [Training and Optimizing ONNX Models with DSPy - ONNX Loop usage gist](https://gist.github.com/ruvnet/ff246cff60a69d00dc161e194d43a889)\n",
    "createdAt": "2026-01-11T05:26:15Z",
    "updatedAt": "2026-01-11T06:18:37Z",
    "author": "parallelarc",
    "authorAvatar": "https://avatars.githubusercontent.com/u/63178075?v=4",
    "authorUrl": "https://github.com/parallelarc",
    "labels": [
      "blog",
      "diffusion"
    ],
    "url": "https://github.com/parallelarc/parallelarc.github.io/issues/2",
    "commentsCount": 0,
    "excerpt": "扩散模型量化：如何在 ONNX 中优雅地处理「重复 N 步」问题 > 当你需要让 Stable Diffusion 在手机或边缘设备上跑起来时，一个关键问题摆在面前：扩散模型需要采样几十甚至上百步，到底该怎么量化？本文将从工程实践角度，帮你理清三种主流方案，并给出明确的选型建议。 ---  问题的诞..."
  }
]